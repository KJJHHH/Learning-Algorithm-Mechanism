# 新型學習演算法
新型學習演算法(2021)：蔡瑞煌教授於政大資管系所開授的課程

## Introduction
The learning algorithm is revised learning mechanism based on two layer net with dynamic adjusting learning rate and three stopping criteria, which is epochs, small residual, and small learning rate, mentioned in cs231n. To overcome the overfitting and learning dilemma issues, two module, reorganizing module and cramming, are proposed to cope with each issues respectively.

## Learning Goals
Predicting copper price.

## Data
- Cleaned data provided by teacher with 18 covariate with dependent variable as price
- TODO: download more data form kaggle to experiment

## Environment
- CPU
- Python 3.10
- Pytorch framework


## Mechanism

### LTS (L11)

### Weight Tuning Module (L6)
- Simple learning
- If acceptable: go to Reorganise module
- If not acceptable: go to Cramming

### Reorganising Module (L7)
- Complex learning
- Removing irrelavent nodes
- Coping with Overfitting problem

### Cramming Module (L9)
- Ruled based adding nodes
- For each case that did not fit well to the model, assign three nodes for the case in the model, where the weights for each nodes is predefined

### Full Module (L11)
```
Notation
# n: picked data to train in traing data
# N: all training data
```
1. Start and INitilasie with hidden node size 1: Initilialise Module
2. Let n = obtaining_LTS, n += 1 
    - The obtaining_LTS
    - if n > N break 
3. Selecting _LTS(n). I(n) = the picked data indexes
4. If the learning goal for picked train data satisfied (max(eps) <= learning goal), Go step 7; Otherwise, there is oen and onlly one k in n that cause contradicton and k = [n]    
5. Save weight
6. Weight tune the current SLFN
    - IF acceptable: go step 7
    - Otherwise, restore weight cram to get acceptable SLFN
7. Reorganise SLFN
8. GO to step 2





## Result
Final model for each module store in acceptable/~

1. Process | Without cramming and LTS
    - Weight tune (obtain acceptable model)
    - Reorganising 

    | Train loss/Test loss| Weight Tune | Reorganise | Nodes after Reorganise |
    | ---------------| -------------- | ----------------| --------------|
    |Trial 1 | 24.27/946.46 | 13.19/716.24 | 24 |


2. Process | Weight tune, Cramming , and Reorganise

| Train loss/Test loss| Weight Tune | Cramming | Reorganise | Nodes after Reorganise |
| ---------------| -------------- | ----------------| --------------| ------ |
Trial 1 | 
<table>
    <tr>
    <td>Train Loss/Test Loss</td>
    <td>Weight Tune</td>
    <td>Cramming</td>
    <td>Reorganise</td>
    <td>Nodes after Cramming</td>
    <td>Nodes after Reorganise</td>
    </tr>
    <tr>
    <td>Trial 1</td>
    <td>28.61/767</td>
    <td>26.28/679</td>
    <td>11.03/612</td>
    <td>164</td>
    <td>not recorded</td>
    </tr>
    <tr>
    <td>Trial 2</td>
    <td>16.23/805.49</td>
    <td>23.17/845.56</td>
    <td>14.52/629.38</td>
    <td>164</td>
    <td>28</td>
    </tr>
</table>

3. Process | Full Path
<table>
    <tr>
    <td>Train Loss/Test Loss</td>
    <td>Weight Tune</td>
    <td>Cramming</td>
    <td>Reorganise</td>
    <td>Full</td>
    <td>Nodes after Cramming</td>
    <td>Nodes after Reorganise</td>
    </tr>
    <tr>
    <td>Trial 1</td>
    <td></td>
    <td></td>
    <td></td>
    <td></td>
    <td></td>
    <td></td>
    </tr>
    <tr>
    <td>Trial 2</td>
    <td></td>
    <td></td>
    <td></td>
    <td></td>
    <td></td>
    <td></td>
    </tr>

</table>


- **WEIGHT TUNE MODULE initialisation for experiment of first two experiment**
    - Hidden nodes: 50
    - Model: Two layers net

